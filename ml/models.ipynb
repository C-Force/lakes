{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(942, 16)\n",
      "(404, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "cols_to_drop = [\n",
    "    'system:index', \n",
    "    'BUFF_DIST',\n",
    "    'Carbonate',\n",
    "    'Cliff',\n",
    "    'ComID',\n",
    "    '.geo',\n",
    "    'Connection',\n",
    "    'FCode',\n",
    "    'FDate',\n",
    "    'FType',\n",
    "    'GNIS_ID',\n",
    "    'GNIS_Name',\n",
    "    'In_NWI',\n",
    "    'Join_Count',\n",
    "    'OBJECTID',\n",
    "    'ORIG_FID',\n",
    "    'Permanent_',\n",
    "    'ReachCode',\n",
    "    'Resolution',\n",
    "    'TARGET_FID',\n",
    "    'Shape_Area',\n",
    "#     'Hectares',\n",
    "    'AreaSqKm',\n",
    "    'Alkaline intrusive',\n",
    "    'Silicic residual',\n",
    "    'Saline lake sediment',\n",
    "    'Non-carbonate',\n",
    "    'Glacial till coarse',\n",
    "    'Extrusive volcanic',\n",
    "    'Eolian sediment fine',\n",
    "    'Mountain/divide',\n",
    "    'Coastal sediment coarse',\n",
    "    'lagoslakei',\n",
    "    'Peak/ridge (cool)',\n",
    "    'Peak/ridge (warm)',\n",
    "    'Peak/ridge',\n",
    "    'Alluvium and coastal sediment fine',\n",
    "    'Eolian sediment coarse',\n",
    "    'Upper slope (cool)',\n",
    "    'Lower slope (cool)',\n",
    "    'Water',\n",
    "    'Hydric',\n",
    "    'Elevation',\n",
    "    'Glacial till clay',\n",
    "    'Colluvial sediment',\n",
    "    'Glacial outwash coarse',\n",
    "#     'physiography',\n",
    "]\n",
    "\n",
    "data = pd.read_csv('lakes_training_mode.csv').drop(cols_to_drop, 1)\n",
    "labels = data.iloc[:,-1]\n",
    "data = data.drop('res', 1)\n",
    "\n",
    "train_feas, test_feas, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.3, shuffle=True, random_state=0)\n",
    "\n",
    "print(train_feas.shape)\n",
    "print(test_feas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize features\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scale = StandardScaler()\n",
    "# scale.fit(train_feas)\n",
    "\n",
    "# train_scaled_feas = train_feas.copy()\n",
    "# train_scaled_feas[train_scaled_feas.columns] = scale.transform(train_feas)\n",
    "\n",
    "# test_scaled_feas = test_feas.copy()\n",
    "# test_scaled_feas[test_scaled_feas.columns] = scale.transform(test_feas)\n",
    "\n",
    "# train_feas = train_scaled_feas\n",
    "# test_feas = test_scaled_feas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1 | feature 6 | Shape_Leng | 0.166233\n",
      "2 | feature 2 | Hectares | 0.103353\n",
      "3 | feature 10 | Valley | 0.078437\n",
      "4 | feature 11 | Valley (narrow) | 0.068435\n",
      "5 | feature 14 | ned | 0.068125\n",
      "6 | feature 13 | mtpi | 0.068059\n",
      "7 | feature 4 | Lower slope (flat) | 0.062604\n",
      "8 | feature 12 | chili | 0.061543\n",
      "9 | feature 7 | Upper slope | 0.059050\n",
      "10 | feature 3 | Lower slope | 0.058670\n",
      "11 | feature 15 | physiography | 0.043803\n",
      "12 | feature 5 | Lower slope (warm) | 0.041688\n",
      "13 | feature 8 | Upper slope (flat) | 0.036670\n",
      "14 | feature 9 | Upper slope (warm) | 0.035355\n",
      "15 | feature 1 | Glacial till loam | 0.024403\n",
      "16 | feature 0 | Glacial lake sediment fine | 0.023573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = RandomForestClassifier(n_estimators=600, max_features=0.1)\n",
    "\n",
    "forest.fit(train_feas, train_labels)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(train_feas.shape[1]):\n",
    "    print(\"%d | feature %d | %s | %f\" % (f + 1, indices[f], list(train_feas.columns.values)[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(train_feas.shape[1]), importances[indices],\n",
    "       color=\"deepskyblue\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(train_feas.shape[1]), indices)\n",
    "plt.xlim([-1, train_feas.shape[1]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Accuracy = 0.755, AUC = 0.758, AP = 0.650, F1 = 0.744, 10-Fold CV: 0.741 (+/- 0.074)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=30)\n",
    "cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy') \n",
    "predictions = model.fit(train_feas, train_labels).predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('KNN')\n",
    "print(\"Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)\" % (acc, auc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network\n",
      "Accuracy = 0.587, AUC = 0.681, AP = 0.916, F1 = 0.700, 10-Fold CV: 0.645 (+/- 0.284)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier()\n",
    "cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy') \n",
    "predictions = model.fit(train_feas, train_labels).predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('Neural Network')\n",
    "print(\"Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)\" % (acc, auc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy = 0.770, AUC = 0.780, AP = 0.635, F1 = 0.749, 10-Fold CV: 0.769 (+/- 0.064)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=0.0001)\n",
    "cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy') \n",
    "predictions = model.fit(train_feas, train_labels).predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('Logistic Regression')\n",
    "print(\"Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)\" % (acc, auc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with rbf\n",
      "Accuracy = 0.693, AP = 0.700, F1 = 0.716, 10-Fold CV: 0.687 (+/- 0.089)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='rbf', C=1, gamma=0.0001)\n",
    "cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy') \n",
    "predictions = model.fit(train_feas, train_labels).predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "# auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('SVC with rbf')\n",
    "print(\"Accuracy = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)\" % (acc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy') \n",
    "predictions = model.fit(train_feas, train_labels).predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('SVC with linear')\n",
    "print(\"Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)\" % (acc, auc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='poly')\n",
    "cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy') \n",
    "predictions = model.fit(train_feas, train_labels).predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('SVC with poly')\n",
    "print(\"Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)\" % (acc, auc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy = 0.797, AUC = 0.797, AP = 0.746, F1 = 0.801, 10-Fold CV: 0.803 (+/- 0.088)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_features=None)\n",
    "cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy') \n",
    "predictions = model.fit(train_feas, train_labels).predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('Decision Tree')\n",
    "print(\"Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)\" % (acc, auc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy = 0.844, AUC = 0.844, AP = 0.785, F1 = 0.844, 10-Fold CV: 0.819 (+/- 0.074)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy') \n",
    "predictions = model.fit(train_feas, train_labels).predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('Random Forest')\n",
    "print(\"Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)\" % (acc, auc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Accuracy = 0.847, AUC = 0.847, AP = 0.782, F1 = 0.846, 10-Fold CV: 0.862 (+/- 0.060)\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy') \n",
    "predictions = model.fit(train_feas, train_labels).predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('Gradient Boosting')\n",
    "print(\"Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)\" % (acc, auc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Accuracy = 0.837, AUC = 0.837, AP = 0.782, F1 = 0.838, 10-Fold CV: 0.843 (+/- 0.078)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(n_estimators=200)\n",
    "cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy') \n",
    "predictions = model.fit(train_feas, train_labels).predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('Gradient Boosting')\n",
    "print(\"Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)\" % (acc, auc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.842, AUC = 0.843, AP = 0.769, F1 = 0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "mlp = MLPClassifier()\n",
    "log = LogisticRegression(C=0.0001)\n",
    "rbf = SVC(kernel='rbf', C=1, gamma=0.0001, probability=True)\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_features=None)\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "gb = GradientBoostingClassifier(n_estimators=100)\n",
    "ada = AdaBoostClassifier(n_estimators=200)\n",
    "\n",
    "model = VotingClassifier(estimators=[('knn', knn), ('mlp', mlp), ('tree', tree), ('rf', rf),\n",
    "                                    ('log', log), ('rbf', rbf), ('gb', gb), ('ada', ada)],\n",
    "                        voting='soft',\n",
    "                        weights=[2, 2, 3, 4, 2, 1, 5, 4])\n",
    "# cv = cross_val_score(model, train_feas, train_labels, cv=10, scoring='accuracy')\n",
    "model.fit(train_feas, train_labels)\n",
    "predictions = model.predict(test_feas)\n",
    "acc = accuracy_score(predictions, test_labels)\n",
    "auc = roc_auc_score(predictions, test_labels)\n",
    "ap = average_precision_score(predictions, test_labels)\n",
    "f1 = f1_score(predictions, test_labels)\n",
    "print('Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f'%(acc, auc, ap, f1))\n",
    "# print('Accuracy = %.3f, AUC = %.3f, AP = %.3f, F1 = %.3f, 10-Fold CV: %0.3f (+/- %0.3f)'%(acc, auc, ap, f1, cv.mean(), cv.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
